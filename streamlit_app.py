import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, recall_score

st.set_page_config(page_title="IBM HR é›¢è·é æ¸¬é»‘å®¢æ¾", layout="wide")

# ==========================================
# 0. å®šç¾©è‡ªå‹•ç¿»è­¯å‡½å¼ (Translation Logic)
# ==========================================
@st.cache_data
def load_and_translate_data(file):
    df = pd.read_csv(file)
    
    # 1. æ¬„ä½åç¨±ç¿»è­¯å°ç…§è¡¨
    columns_translation = {
        'Age': 'å¹´é½¡', 'Attrition': 'é›¢è·', 'BusinessTravel': 'å•†å‹™å·®æ—…', 'DailyRate': 'æ—¥è–ª',
        'Department': 'éƒ¨é–€', 'DistanceFromHome': 'é€šå‹¤è·é›¢', 'Education': 'æ•™è‚²ç¨‹åº¦',
        'EducationField': 'æ•™è‚²é ˜åŸŸ', 'EmployeeCount': 'å“¡å·¥æ•¸é‡', 'EmployeeNumber': 'å“¡å·¥ç·¨è™Ÿ',
        'EnvironmentSatisfaction': 'ç’°å¢ƒæ»¿æ„åº¦', 'Gender': 'æ€§åˆ¥', 'HourlyRate': 'æ™‚è–ª',
        'JobInvolvement': 'å·¥ä½œæŠ•å…¥åº¦', 'JobLevel': 'è·ç´š', 'JobRole': 'è·ä½è§’è‰²',
        'JobSatisfaction': 'å·¥ä½œæ»¿æ„åº¦', 'MaritalStatus': 'å©šå§»ç‹€æ³', 'MonthlyIncome': 'æœˆæ”¶å…¥',
        'MonthlyRate': 'æœˆè²»ç‡', 'NumCompaniesWorked': 'æ›¾å·¥ä½œå…¬å¸æ•¸é‡', 'Over18': 'å¹´æ»¿18æ­²',
        'OverTime': 'åŠ ç­', 'PercentSalaryHike': 'åŠ è–ªç™¾åˆ†æ¯”', 'PerformanceRating': 'ç¸¾æ•ˆè©•ç´š',
        'RelationshipSatisfaction': 'äººéš›é—œä¿‚æ»¿æ„åº¦', 'StandardHours': 'æ¨™æº–å·¥æ™‚',
        'StockOptionLevel': 'è‚¡ç¥¨æœŸæ¬Šç´šåˆ¥', 'TotalWorkingYears': 'ç¸½å·¥ä½œå¹´è³‡',
        'TrainingTimesLastYear': 'å»å¹´åŸ¹è¨“æ¬¡æ•¸', 'WorkLifeBalance': 'å·¥ä½œç”Ÿæ´»å¹³è¡¡',
        'YearsAtCompany': 'åœ¨è·å¹´è³‡', 'YearsInCurrentRole': 'ç›®å‰è·ä½å¹´è³‡',
        'YearsSinceLastPromotion': 'è·é›¢ä¸Šæ¬¡æ™‰å‡å¹´è³‡', 'YearsWithCurrManager': 'èˆ‡ç›®å‰ç¶“ç†å…±äº‹å¹´è³‡'
    }

    # 2. å…§å®¹å€¼ç¿»è­¯å°ç…§è¡¨
    values_translation = {
        'Attrition': {'Yes': 'æ˜¯', 'No': 'å¦'},
        'BusinessTravel': {'Travel_Rarely': 'å¾ˆå°‘å‡ºå·®', 'Travel_Frequently': 'ç¶“å¸¸å‡ºå·®', 'Non-Travel': 'ä¸å‡ºå·®'},
        'Department': {'Sales': 'éŠ·å”®éƒ¨', 'Research & Development': 'ç ”ç™¼éƒ¨', 'Human Resources': 'äººåŠ›è³‡æºéƒ¨'},
        'EducationField': {'Life Sciences': 'ç”Ÿå‘½ç§‘å­¸', 'Other': 'å…¶ä»–', 'Medical': 'é†«ç™‚', 'Marketing': 'å¸‚å ´è¡ŒéŠ·', 'Technical Degree': 'æŠ€è¡“å­¸ä½', 'Human Resources': 'äººåŠ›è³‡æº'},
        'Gender': {'Female': 'å¥³æ€§', 'Male': 'ç”·æ€§'},
        'JobRole': {'Sales Executive': 'éŠ·å”®ä¸»ç®¡', 'Research Scientist': 'ç ”ç©¶ç§‘å­¸å®¶', 'Laboratory Technician': 'å¯¦é©—å®¤æŠ€è¡“å“¡', 'Manufacturing Director': 'è£½é€ ç¸½ç›£', 'Healthcare Representative': 'é†«ç™‚ä»£è¡¨', 'Manager': 'ç¶“ç†', 'Sales Representative': 'éŠ·å”®ä»£è¡¨', 'Research Director': 'ç ”ç©¶ç¸½ç›£', 'Human Resources': 'äººåŠ›è³‡æºå°ˆå“¡'},
        'MaritalStatus': {'Single': 'å–®èº«', 'Married': 'å·²å©š', 'Divorced': 'é›¢å©š'},
        'Over18': {'Y': 'æ˜¯'},
        'OverTime': {'Yes': 'æ˜¯', 'No': 'å¦'}
    }

    # åŸ·è¡Œç¿»è­¯
    for col, trans_dict in values_translation.items():
        if col in df.columns:
            df[col] = df[col].replace(trans_dict)

    df.rename(columns=columns_translation, inplace=True)
    return df

# ==========================================
# 1. ä»‹é¢é–‹å§‹
# ==========================================
st.title("ğŸ“Š IBM HR Analyticsï¼šé›¢è·æ•¸æ“šé»‘å®¢æ¾ (å…¨ä¸­æ–‡ç‰ˆ)")
st.markdown("""
### ç«¶è³½ä»»å‹™ï¼š
è«‹ä¸Šå‚³ IBM åŸå§‹è‹±æ–‡è³‡æ–™é›†ï¼Œç³»çµ±å°‡è‡ªå‹•ç¿»è­¯ä¸¦é€²è¡Œåˆ†æã€‚
æ‰¾å‡º **ã€Œå°è‡´å“¡å·¥é›¢è·çš„ 3 å¤§é—œéµå…ƒå…‡ã€**ï¼Œä¸¦æ“šæ­¤æå‡ºæ”¹å–„ç­–ç•¥ã€‚
""")

# è³‡æ–™ä¸Šå‚³å€
st.sidebar.header("ğŸ“‚ æ­¥é©Ÿ 1ï¼šä¸Šå‚³è³‡æ–™é›†")
uploaded_file = st.sidebar.file_uploader("è«‹ä¸Šå‚³è‹±æ–‡ç‰ˆ csv æª” (WA_Fn-UseC_-HR-Employee-Attrition.csv)", type=["csv"])

if uploaded_file is not None:
    # å‘¼å«ç¿»è­¯å‡½å¼
    df = load_and_translate_data(uploaded_file)
    st.success("âœ… è³‡æ–™è¼‰å…¥ä¸¦ç¿»è­¯æˆåŠŸï¼")
else:
    st.info("ğŸ‘† è«‹å¾å´é‚Šæ¬„ä¸Šå‚³ CSV æª”æ¡ˆã€‚")
    st.stop()

# ==========================================
# 2. æ•¸æ“šæ¦‚è¦½
# ==========================================
with st.expander("ğŸ” é»æ“Šæª¢è¦–å®Œæ•´è³‡æ–™ (å·²ä¸­æ–‡åŒ–)", expanded=False):
    st.dataframe(df)
    st.write(f"ç¸½ç­†æ•¸ï¼š{df.shape[0]} ä½å“¡å·¥ | æ¬„ä½æ•¸ï¼š{df.shape[1]}")

# ==========================================
# 3. è‡ªå‹•åŒ–é—œè¯åˆ†æ
# ==========================================
st.header("1. é›¢è·åŸå› æ¢ç´¢ (EDA)")
st.write("ç³»çµ±è‡ªå‹•åˆ†æå„è®Šæ•¸èˆ‡ **é›¢è·** çš„é—œä¿‚ã€‚")

# å°‡é›¢è·è½‰å›æ•¸å­—ä»¥ä¾¿è¨ˆç®— (æ˜¯=1, å¦=0)
if 'é›¢è·' in df.columns:
    df['é›¢è·_æ•¸å€¼'] = df['é›¢è·'].apply(lambda x: 1 if x == 'æ˜¯' else 0)
    
    # æ’é™¤éæ•¸å€¼æ¬„ä½ï¼Œåªç•™ä¸‹é©åˆåˆ†æçš„
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    # åŠ ä¸Šä¸€äº›é‡è¦çš„é¡åˆ¥æ¬„ä½
    categorical_cols = ['åŠ ç­', 'å•†å‹™å·®æ—…', 'éƒ¨é–€', 'æ€§åˆ¥', 'å©šå§»ç‹€æ³']
    
    all_factors = numeric_cols + categorical_cols
    if 'é›¢è·_æ•¸å€¼' in all_factors: all_factors.remove('é›¢è·_æ•¸å€¼')

    factors = st.multiselect("è«‹é¸æ“‡ä½ å€‘æ‡·ç–‘çš„å½±éŸ¿å› å­ï¼š", 
                             all_factors,
                             default=['æœˆæ”¶å…¥', 'å¹´é½¡', 'é€šå‹¤è·é›¢', 'å·¥ä½œæ»¿æ„åº¦', 'åŠ ç­'])
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        target_factor = st.selectbox("è©³ç´°è§€å¯Ÿå“ªä¸€å€‹å› å­ï¼Ÿ", factors)
        
        # åˆ¤æ–·æ˜¯æ•¸å€¼é‚„æ˜¯é¡åˆ¥
        if df[target_factor].dtype != 'object':
            # æ•¸å€¼å‹ç”¨ç›’é¬šåœ–
            fig = px.box(df, x="é›¢è·", y=target_factor, color="é›¢è·", 
                         title=f"é›¢è·èˆ‡åœ¨è·è€…çš„ {target_factor} å·®ç•°",
                         color_discrete_map={'æ˜¯':'#FF4B4B', 'å¦':'#1F77B4'})
            st.plotly_chart(fig, use_container_width=True)
        else:
            # é¡åˆ¥å‹ç”¨é•·æ¢åœ– (è¨ˆç®—é›¢è·ç‡)
            # å…ˆè¨ˆç®—å„çµ„çš„é›¢è·ç‡
            group_data = df.groupby(target_factor)['é›¢è·_æ•¸å€¼'].mean().reset_index()
            group_data['é›¢è·ç‡%'] = (group_data['é›¢è·_æ•¸å€¼'] * 100).round(1)
            
            fig = px.bar(group_data, x=target_factor, y='é›¢è·ç‡%', 
                         title=f"ä¸åŒ {target_factor} çš„é›¢è·ç‡åˆ†æ",
                         text='é›¢è·ç‡%', color='é›¢è·ç‡%')
            st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("ğŸ”¥ ç›¸é—œæ€§ç†±åœ– (æ•¸å€¼å‹)")
        # åªå–æ•¸å€¼å‹æ¬„ä½åšç†±åœ–
        corr_cols = [c for c in factors if c in numeric_cols] + ['é›¢è·_æ•¸å€¼']
        if len(corr_cols) > 1:
            corr_matrix = df[corr_cols].corr()[['é›¢è·_æ•¸å€¼']].sort_values(by='é›¢è·_æ•¸å€¼', ascending=False)
            fig_corr = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
            st.plotly_chart(fig_corr, use_container_width=True)
        else:
            st.write("è«‹é¸æ“‡æ›´å¤šæ•¸å€¼å‹å› å­ä»¥é¡¯ç¤ºç†±åœ–")

# ==========================================
# 4. AI é›¢è·é æ¸¬æ¨¡å‹
# ==========================================
st.divider()
st.header("2. AI é æ¸¬æ¨¡å‹ç«¶è³½")

col_model_1, col_model_2 = st.columns(2)

with col_model_1:
    st.subheader("âš™ï¸ æ¨¡å‹åƒæ•¸è¨­å®š")
    n_estimators = st.slider("æ±ºç­–æ¨¹æ•¸é‡", 10, 200, 100)
    test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.5, 0.2)
    
    # è³‡æ–™å‰è™•ç†ï¼šé¡åˆ¥è½‰æ•¸å­— (One-Hot Encoding)
    # æ’é™¤ä¸å¿…è¦çš„æ¬„ä½
    drop_cols = ['é›¢è·', 'å“¡å·¥æ•¸é‡', 'å“¡å·¥ç·¨è™Ÿ', 'å¹´æ»¿18æ­²', 'æ¨™æº–å·¥æ™‚', 'é›¢è·_æ•¸å€¼']
    df_ml = pd.get_dummies(df.drop(drop_cols, axis=1, errors='ignore'), drop_first=True)
    
    if st.button("ğŸš€ è¨“ç·´æ¨¡å‹ä¸¦é æ¸¬"):
        X = df_ml
        y = df['é›¢è·_æ•¸å€¼']
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        
        st.session_state['model_result'] = {'acc': acc, 'recall': recall, 'model': model, 'features': X.columns}

with col_model_2:
    if 'model_result' in st.session_state:
        res = st.session_state['model_result']
        st.subheader("ğŸ† æ¨¡å‹æˆç¸¾å–®")
        c1, c2 = st.columns(2)
        c1.metric("æº–ç¢ºç‡ (Accuracy)", f"{res['acc']*100:.1f}%")
        c2.metric("å¬å›ç‡ (Recall)", f"{res['recall']*100:.1f}%", delta_color="inverse")
        
        st.write("---")
        st.write("**å°é›¢è·å½±éŸ¿æœ€å¤§çš„å‰ 5 å€‹ç‰¹å¾µï¼š**")
        feat_importances = pd.Series(res['model'].feature_importances_, index=res['features'])
        st.bar_chart(feat_importances.nlargest(5))

# ==========================================
# 5. ç­–ç•¥ææ¡ˆ
# ==========================================
st.divider()
st.header("3. ç­–ç•¥ææ¡ˆ")
st.text_area("Q1: æ ¹æ“šæ•¸æ“šï¼Œå“ªä¸‰å€‹å› ç´ æ˜¯å°è‡´é›¢è·çš„ä¸»å› ï¼Ÿ")
st.text_area("Q2: é‡å°é€™äº›ä¸»å› ï¼Œå»ºè­°æ¡å–çš„å…·é«”è¡Œå‹•ï¼Ÿ")
