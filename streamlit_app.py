import streamlit as st
import pandas as pd
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, recall_score

st.set_page_config(page_title="IBM HR é›¢è·é æ¸¬é»‘å®¢æ¾", layout="wide")

# ==========================================
# 0. å¼·åŠ›ç¿»è­¯å‡½å¼ (ç¢ºä¿è‹±æ–‡æ¬„ä½ä¸€å®šæœƒè®Šæˆä¸­æ–‡)
# ==========================================
@st.cache_data
def load_and_translate_data(file):
    try:
        df = pd.read_csv(file)
        
        # 1. æ¬„ä½åç¨±å°ç…§è¡¨ (English -> Chinese)
        columns_map = {
            'Age': 'å¹´é½¡', 'Attrition': 'é›¢è·', 'BusinessTravel': 'å•†å‹™å·®æ—…', 'DailyRate': 'æ—¥è–ª',
            'Department': 'éƒ¨é–€', 'DistanceFromHome': 'é€šå‹¤è·é›¢', 'Education': 'æ•™è‚²ç¨‹åº¦',
            'EducationField': 'æ•™è‚²é ˜åŸŸ', 'EmployeeCount': 'å“¡å·¥æ•¸é‡', 'EmployeeNumber': 'å“¡å·¥ç·¨è™Ÿ',
            'EnvironmentSatisfaction': 'ç’°å¢ƒæ»¿æ„åº¦', 'Gender': 'æ€§åˆ¥', 'HourlyRate': 'æ™‚è–ª',
            'JobInvolvement': 'å·¥ä½œæŠ•å…¥åº¦', 'JobLevel': 'è·ç´š', 'JobRole': 'è·ä½è§’è‰²',
            'JobSatisfaction': 'å·¥ä½œæ»¿æ„åº¦', 'MaritalStatus': 'å©šå§»ç‹€æ³', 'MonthlyIncome': 'æœˆæ”¶å…¥',
            'MonthlyRate': 'æœˆè²»ç‡', 'NumCompaniesWorked': 'æ›¾å·¥ä½œå…¬å¸æ•¸é‡', 'Over18': 'å¹´æ»¿18æ­²',
            'OverTime': 'åŠ ç­', 'PercentSalaryHike': 'åŠ è–ªç™¾åˆ†æ¯”', 'PerformanceRating': 'ç¸¾æ•ˆè©•ç´š',
            'RelationshipSatisfaction': 'äººéš›é—œä¿‚æ»¿æ„åº¦', 'StandardHours': 'æ¨™æº–å·¥æ™‚',
            'StockOptionLevel': 'è‚¡ç¥¨æœŸæ¬Šç´šåˆ¥', 'TotalWorkingYears': 'ç¸½å·¥ä½œå¹´è³‡',
            'TrainingTimesLastYear': 'å»å¹´åŸ¹è¨“æ¬¡æ•¸', 'WorkLifeBalance': 'å·¥ä½œç”Ÿæ´»å¹³è¡¡',
            'YearsAtCompany': 'åœ¨è·å¹´è³‡', 'YearsInCurrentRole': 'ç›®å‰è·ä½å¹´è³‡',
            'YearsSinceLastPromotion': 'è·é›¢ä¸Šæ¬¡æ™‰å‡å¹´è³‡', 'YearsWithCurrManager': 'èˆ‡ç›®å‰ç¶“ç†å…±äº‹å¹´è³‡'
        }

        # 2. å…§å®¹å€¼å°ç…§è¡¨
        values_map = {
            'Attrition': {'Yes': 'æ˜¯', 'No': 'å¦'},
            'BusinessTravel': {'Travel_Rarely': 'å¾ˆå°‘å‡ºå·®', 'Travel_Frequently': 'ç¶“å¸¸å‡ºå·®', 'Non-Travel': 'ä¸å‡ºå·®'},
            'Department': {'Sales': 'éŠ·å”®éƒ¨', 'Research & Development': 'ç ”ç™¼éƒ¨', 'Human Resources': 'äººåŠ›è³‡æºéƒ¨'},
            'Gender': {'Female': 'å¥³æ€§', 'Male': 'ç”·æ€§'},
            'MaritalStatus': {'Single': 'å–®èº«', 'Married': 'å·²å©š', 'Divorced': 'é›¢å©š'},
            'OverTime': {'Yes': 'æ˜¯', 'No': 'å¦'}
        }

        # å…ˆç¿»è­¯å…§å®¹
        for col, trans_dict in values_map.items():
            if col in df.columns:
                df[col] = df[col].replace(trans_dict)

        # å†ç¿»è­¯æ¬„ä½åç¨±
        df.rename(columns=columns_map, inplace=True)
        
        return df
    except Exception as e:
        st.error(f"è³‡æ–™è®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return pd.DataFrame()

# ==========================================
# 1. ä¸»ç¨‹å¼é–‹å§‹
# ==========================================
st.title("ğŸ“Š IBM HR Analyticsï¼šé›¢è·æ•¸æ“šé»‘å®¢æ¾")

# å´é‚Šæ¬„ä¸Šå‚³
st.sidebar.header("ğŸ“‚ æ­¥é©Ÿ 1ï¼šä¸Šå‚³è³‡æ–™")
uploaded_file = st.sidebar.file_uploader("è«‹ä¸Šå‚³è‹±æ–‡ç‰ˆ csv æª”", type=["csv"])

if uploaded_file is not None:
    df = load_and_translate_data(uploaded_file)
    if df.empty:
        st.stop()
    st.success("âœ… è³‡æ–™è¼‰å…¥ä¸¦ç¿»è­¯æˆåŠŸï¼")
else:
    st.info("ğŸ‘† è«‹å¾å´é‚Šæ¬„ä¸Šå‚³ CSV æª”æ¡ˆ (WA_Fn-UseC_-HR-Employee-Attrition.csv)ã€‚")
    st.stop()

# ==========================================
# 2. æ•¸æ“šæ¢ç´¢ (EDA) - ä¿®å¾©äº†åœ–è¡¨éŒ¯èª¤èˆ‡KeyError
# ==========================================
st.header("1. é›¢è·åŸå› æ¢ç´¢")

# å»ºç«‹é›¢è·æ•¸å€¼æ¬„ä½ (ç”¨æ–¼è¨ˆç®—)
if 'é›¢è·' in df.columns:
    df['é›¢è·_æ•¸å€¼'] = df['é›¢è·'].apply(lambda x: 1 if x == 'æ˜¯' else 0)

# å®šç¾©å„ç¨®æ¬„ä½é¡å‹
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
# é€™äº›æ˜¯æˆ‘å€‘å¸Œæœ›å¼·åˆ¶ç”¨ã€Œé•·æ¢åœ–ã€çœ‹çš„æ¬„ä½
ordinal_cols = ['å·¥ä½œæ»¿æ„åº¦', 'ç’°å¢ƒæ»¿æ„åº¦', 'äººéš›é—œä¿‚æ»¿æ„åº¦', 'å·¥ä½œæŠ•å…¥åº¦', 'ç¸¾æ•ˆè©•ç´š', 'è·ç´š']
categorical_cols = ['åŠ ç­', 'å•†å‹™å·®æ—…', 'éƒ¨é–€', 'æ€§åˆ¥', 'å©šå§»ç‹€æ³', 'æ•™è‚²é ˜åŸŸ', 'è·ä½è§’è‰²'] + ordinal_cols

# ç¢ºä¿ä¸‹æ‹‰é¸å–®åªé¡¯ç¤ºã€ŒçœŸæ­£å­˜åœ¨ã€çš„æ¬„ä½ (é˜²å‘†æ©Ÿåˆ¶)
valid_options = [c for c in (numeric_cols + categorical_cols) if c in df.columns]
if 'é›¢è·_æ•¸å€¼' in valid_options: valid_options.remove('é›¢è·_æ•¸å€¼')

# è¨­å®šé è¨­å€¼ (å¦‚æœæ¬„ä½å­˜åœ¨æ‰è¨­ç‚ºé è¨­ï¼Œé¿å…å ±éŒ¯)
default_opts = [c for c in ['æœˆæ”¶å…¥', 'å¹´é½¡', 'åŠ ç­', 'å·¥ä½œæ»¿æ„åº¦'] if c in df.columns]

factors = st.multiselect("é¸æ“‡åˆ†æå› å­ï¼š", valid_options, default=default_opts)

col1, col2 = st.columns([2, 1])

with col1:
    if factors:
        target_factor = st.selectbox("è©³ç´°è§€å¯Ÿå“ªä¸€å€‹å› å­ï¼Ÿ", factors)
        
        # æ™ºæ…§åˆ¤æ–·åœ–è¡¨é¡å‹ï¼šå¦‚æœæ˜¯é¡åˆ¥ï¼Œæˆ–æ•¸å€¼ç¨®é¡å¾ˆå°‘(å¦‚1-4åˆ†)ï¼Œéƒ½ç”¨é•·æ¢åœ–
        is_categorical = (target_factor in categorical_cols) or \
                         (df[target_factor].dtype == 'object') or \
                         (df[target_factor].nunique() <= 5)
        
        if is_categorical:
            # === ç•«é•·æ¢åœ– (é¡¯ç¤ºé›¢è·ç‡ %) ===
            group_data = df.groupby(target_factor)['é›¢è·_æ•¸å€¼'].agg(['mean', 'count']).reset_index()
            group_data.columns = [target_factor, 'é›¢è·ç‡', 'äººæ•¸']
            group_data['é›¢è·ç‡%'] = (group_data['é›¢è·ç‡'] * 100).round(1)
            
            fig = px.bar(group_data, x=target_factor, y='é›¢è·ç‡%', 
                         title=f"ã€{target_factor}ã€‘å„çµ„åˆ¥çš„é›¢è·ç‡",
                         text='é›¢è·ç‡%', color='é›¢è·ç‡%', color_continuous_scale='Reds')
            fig.update_traces(texttemplate='%{text}%', textposition='outside')
            st.plotly_chart(fig, use_container_width=True)
        else:
            # === ç•«ç›’é¬šåœ– (é¡¯ç¤ºåˆ†ä½ˆå·®ç•°) ===
            fig = px.box(df, x="é›¢è·", y=target_factor, color="é›¢è·", 
                         title=f"é›¢è·èˆ‡åœ¨è·è€…çš„ã€{target_factor}ã€‘å·®ç•°",
                         color_discrete_map={'æ˜¯':'#FF4B4B', 'å¦':'#1F77B4'})
            st.plotly_chart(fig, use_container_width=True)
            
            # é¡¯ç¤ºå¹³å‡æ•¸å·®ç•°
            avg_yes = df[df['é›¢è·']=='æ˜¯'][target_factor].mean()
            avg_no = df[df['é›¢è·']=='å¦'][target_factor].mean()
            diff_pct = ((avg_yes - avg_no) / avg_no) * 100
            
            m1, m2, m3 = st.columns(3)
            m1.metric("é›¢è·è€…å¹³å‡", f"{avg_yes:.1f}")
            m2.metric("åœ¨è·è€…å¹³å‡", f"{avg_no:.1f}")
            m3.metric("å·®ç•°", f"{diff_pct:+.1f}%", delta_color="inverse")

with col2:
    st.subheader("ğŸ”¥ ç›¸é—œæ€§ç†±åœ–")
    # åªå–æ•¸å€¼å‹æ¬„ä½
    corr_cols = [c for c in factors if c in numeric_cols] + ['é›¢è·_æ•¸å€¼']
    # å»é™¤é‡è¤‡ä¸¦ç¢ºèªæ¬„ä½å­˜åœ¨
    corr_cols = list(set([c for c in corr_cols if c in df.columns]))
    
    if len(corr_cols) > 1:
        corr_matrix = df[corr_cols].corr()[['é›¢è·_æ•¸å€¼']].sort_values(by='é›¢è·_æ•¸å€¼', ascending=False)
        fig_corr = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
        st.plotly_chart(fig_corr, use_container_width=True)
    else:
        st.write("è«‹é¸æ“‡æ›´å¤šæ•¸å€¼å› å­")

# ==========================================
# 3. AI é æ¸¬æ¨¡å‹
# ==========================================
st.divider()
st.header("2. AI é›¢è·é æ¸¬æ¨¡å‹")

c_AI_1, c_AI_2 = st.columns(2)
with c_AI_1:
    n_estimators = st.slider("æ±ºç­–æ¨¹æ•¸é‡", 10, 200, 100)
    
    # ç°¡å–®ç‰¹å¾µå·¥ç¨‹
    drop_cols = ['é›¢è·', 'å“¡å·¥æ•¸é‡', 'å“¡å·¥ç·¨è™Ÿ', 'å¹´æ»¿18æ­²', 'æ¨™æº–å·¥æ™‚', 'é›¢è·_æ•¸å€¼']
    # åªåˆªé™¤å­˜åœ¨çš„æ¬„ä½
    real_drop = [c for c in drop_cols if c in df.columns]
    
    df_ml = pd.get_dummies(df.drop(real_drop, axis=1), drop_first=True)
    
    if st.button("ğŸš€ è¨“ç·´æ¨¡å‹"):
        X = df_ml
        y = df['é›¢è·_æ•¸å€¼']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        
        st.session_state['model_res'] = {'acc': acc, 'recall': recall, 'model': model, 'feat': X.columns}

with c_AI_2:
    if 'model_res' in st.session_state:
        res = st.session_state['model_res']
        st.subheader("ğŸ† æ¨¡å‹çµæœ")
        st.metric("æº–ç¢ºç‡", f"{res['acc']*100:.1f}%")
        st.metric("å¬å›ç‡ (æŠ“åˆ°é›¢è·è€…çš„æ¯”ä¾‹)", f"{res['recall']*100:.1f}%")
        
        st.write("**é—œéµé›¢è·å› å­ (Top 5):**")
        imp = pd.Series(res['model'].feature_importances_, index=res['feat'])
        st.bar_chart(imp.nlargest(5))

# ==========================================
# 4. ç­–ç•¥ææ¡ˆå€
# ==========================================
st.divider()
st.header("3. ç­–ç•¥ææ¡ˆ")
st.text_area("Q1: æ•¸æ“šé¡¯ç¤ºå“ªä¸‰å€‹å› ç´ æ˜¯é›¢è·ä¸»å› ï¼Ÿ")
