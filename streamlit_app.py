import streamlit as st
import pandas as pd
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, recall_score

st.set_page_config(page_title="IBM HR é›¢è·é æ¸¬é»‘å®¢æ¾", layout="wide")

# ==========================================
# 0. å¼·åŠ›ç¿»è­¯å‡½å¼ (ç¢ºä¿è‹±æ–‡æ¬„ä½ä¸€å®šæœƒè®Šæˆä¸­æ–‡)
# ==========================================
@st.cache_data
def load_and_translate_data(file):
    try:
        df = pd.read_csv(file)
        
        # 1. æ¬„ä½åç¨±å°ç…§è¡¨ (English -> Chinese)
        columns_map = {
            'Age': 'å¹´é½¡', 'Attrition': 'é›¢è·', 'BusinessTravel': 'å•†å‹™å·®æ—…', 'DailyRate': 'æ—¥è–ª',
            'Department': 'éƒ¨é–€', 'DistanceFromHome': 'é€šå‹¤è·é›¢', 'Education': 'æ•™è‚²ç¨‹åº¦',
            'EducationField': 'æ•™è‚²é ˜åŸŸ', 'EmployeeCount': 'å“¡å·¥æ•¸é‡', 'EmployeeNumber': 'å“¡å·¥ç·¨è™Ÿ',
            'EnvironmentSatisfaction': 'ç’°å¢ƒæ»¿æ„åº¦', 'Gender': 'æ€§åˆ¥', 'HourlyRate': 'æ™‚è–ª',
            'JobInvolvement': 'å·¥ä½œæŠ•å…¥åº¦', 'JobLevel': 'è·ç´š', 'JobRole': 'è·ä½è§’è‰²',
            'JobSatisfaction': 'å·¥ä½œæ»¿æ„åº¦', 'MaritalStatus': 'å©šå§»ç‹€æ³', 'MonthlyIncome': 'æœˆæ”¶å…¥',
            'MonthlyRate': 'æœˆè²»ç‡', 'NumCompaniesWorked': 'æ›¾å·¥ä½œå…¬å¸æ•¸é‡', 'Over18': 'å¹´æ»¿18æ­²',
            'OverTime': 'åŠ ç­', 'PercentSalaryHike': 'åŠ è–ªç™¾åˆ†æ¯”', 'PerformanceRating': 'ç¸¾æ•ˆè©•ç´š',
            'RelationshipSatisfaction': 'äººéš›é—œä¿‚æ»¿æ„åº¦', 'StandardHours': 'æ¨™æº–å·¥æ™‚',
            'StockOptionLevel': 'è‚¡ç¥¨æœŸæ¬Šç´šåˆ¥', 'TotalWorkingYears': 'ç¸½å·¥ä½œå¹´è³‡',
            'TrainingTimesLastYear': 'å»å¹´åŸ¹è¨“æ¬¡æ•¸', 'WorkLifeBalance': 'å·¥ä½œç”Ÿæ´»å¹³è¡¡',
            'YearsAtCompany': 'åœ¨è·å¹´è³‡', 'YearsInCurrentRole': 'ç›®å‰è·ä½å¹´è³‡',
            'YearsSinceLastPromotion': 'è·é›¢ä¸Šæ¬¡æ™‰å‡å¹´è³‡', 'YearsWithCurrManager': 'èˆ‡ç›®å‰ç¶“ç†å…±äº‹å¹´è³‡'
        }

        # 2. å…§å®¹å€¼å°ç…§è¡¨
        values_map = {
            'Attrition': {'Yes': 'æ˜¯', 'No': 'å¦'},
            'BusinessTravel': {'Travel_Rarely': 'å¾ˆå°‘å‡ºå·®', 'Travel_Frequently': 'ç¶“å¸¸å‡ºå·®', 'Non-Travel': 'ä¸å‡ºå·®'},
            'Department': {'Sales': 'éŠ·å”®éƒ¨', 'Research & Development': 'ç ”ç™¼éƒ¨', 'Human Resources': 'äººåŠ›è³‡æºéƒ¨'},
            'Gender': {'Female': 'å¥³æ€§', 'Male': 'ç”·æ€§'},
            'MaritalStatus': {'Single': 'å–®èº«', 'Married': 'å·²å©š', 'Divorced': 'é›¢å©š'},
            'OverTime': {'Yes': 'æ˜¯', 'No': 'å¦'}
        }

        # å…ˆç¿»è­¯å…§å®¹
        for col, trans_dict in values_map.items():
            if col in df.columns:
                df[col] = df[col].replace(trans_dict)

        # å†ç¿»è­¯æ¬„ä½åç¨±
        df.rename(columns=columns_map, inplace=True)
        
        return df
    except Exception as e:
        st.error(f"è³‡æ–™è®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return pd.DataFrame()

# ==========================================
# 1. ä¸»ç¨‹å¼é–‹å§‹
# ==========================================
st.title("ğŸ“Š IBM HR Analyticsï¼šé›¢è·æ•¸æ“šé»‘å®¢æ¾")
st.markdown("---")

# å´é‚Šæ¬„ä¸Šå‚³
st.sidebar.header("ğŸ“‚ æ­¥é©Ÿ 1ï¼šä¸Šå‚³è³‡æ–™")
uploaded_file = st.sidebar.file_uploader("è«‹ä¸Šå‚³è‹±æ–‡ç‰ˆ csv æª” (WA_Fn-UseC_-HR-Employee-Attrition.csv)", type=["csv"])

if uploaded_file is not None:
    df = load_and_translate_data(uploaded_file)
    if df.empty:
        st.stop()
    st.sidebar.success("âœ… è³‡æ–™è¼‰å…¥ä¸¦ç¿»è­¯æˆåŠŸï¼")
else:
    st.info("ğŸ‘† è«‹å¾å´é‚Šæ¬„ä¸Šå‚³ CSV æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
    st.stop()

# ==========================================
# 2. æ•¸æ“šæ¢ç´¢ (EDA)
# ==========================================
st.header("1. é›¢è·åŸå› æ¢ç´¢ (Data Discovery)")

# å»ºç«‹é›¢è·æ•¸å€¼æ¬„ä½ (ç”¨æ–¼è¨ˆç®—)
if 'é›¢è·' in df.columns:
    df['é›¢è·_æ•¸å€¼'] = df['é›¢è·'].apply(lambda x: 1 if x == 'æ˜¯' else 0)

# å®šç¾©å„ç¨®æ¬„ä½é¡å‹
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
ordinal_cols = ['å·¥ä½œæ»¿æ„åº¦', 'ç’°å¢ƒæ»¿æ„åº¦', 'äººéš›é—œä¿‚æ»¿æ„åº¦', 'å·¥ä½œæŠ•å…¥åº¦', 'ç¸¾æ•ˆè©•ç´š', 'è·ç´š']
categorical_cols = ['åŠ ç­', 'å•†å‹™å·®æ—…', 'éƒ¨é–€', 'æ€§åˆ¥', 'å©šå§»ç‹€æ³', 'æ•™è‚²é ˜åŸŸ', 'è·ä½è§’è‰²'] + ordinal_cols

# é˜²å‘†æ©Ÿåˆ¶ï¼šç¢ºä¿æ¬„ä½å­˜åœ¨
valid_options = [c for c in (numeric_cols + categorical_cols) if c in df.columns]
if 'é›¢è·_æ•¸å€¼' in valid_options: valid_options.remove('é›¢è·_æ•¸å€¼')
default_opts = [c for c in ['æœˆæ”¶å…¥', 'å¹´é½¡', 'åŠ ç­', 'å·¥ä½œæ»¿æ„åº¦'] if c in df.columns]

factors = st.multiselect("è«‹é¸æ“‡ä½ å€‘æƒ³åˆ†æçš„å› å­ï¼š", valid_options, default=default_opts)

col1, col2 = st.columns([2, 1])

with col1:
    if factors:
        target_factor = st.selectbox("è©³ç´°è§€å¯Ÿå“ªä¸€å€‹å› å­ï¼Ÿ", factors)
        
        # æ™ºæ…§åœ–è¡¨åˆ‡æ›ï¼šé¡åˆ¥/å°‘æ•¸æ•¸å€¼ -> é•·æ¢åœ–ï¼›é€£çºŒæ•¸å€¼ -> ç›’é¬šåœ–
        is_categorical = (target_factor in categorical_cols) or \
                         (df[target_factor].dtype == 'object') or \
                         (df[target_factor].nunique() <= 5)
        
        if is_categorical:
            # === é•·æ¢åœ– (Bar Chart) ===
            group_data = df.groupby(target_factor)['é›¢è·_æ•¸å€¼'].agg(['mean', 'count']).reset_index()
            group_data.columns = [target_factor, 'é›¢è·ç‡', 'äººæ•¸']
            group_data['é›¢è·ç‡%'] = (group_data['é›¢è·ç‡'] * 100).round(1)
            
            fig = px.bar(group_data, x=target_factor, y='é›¢è·ç‡%', 
                         title=f"ã€{target_factor}ã€‘å„çµ„åˆ¥é›¢è·ç‡åˆ†æ",
                         text='é›¢è·ç‡%', color='é›¢è·ç‡%', color_continuous_scale='Reds')
            fig.update_traces(texttemplate='%{text}%', textposition='outside')
            st.plotly_chart(fig, use_container_width=True)
            
            # è‡ªå‹•è§£è®€
            max_row = group_data.loc[group_data['é›¢è·ç‡%'].idxmax()]
            st.info(f"ğŸ’¡ ç™¼ç¾ï¼š **{max_row[target_factor]}** çš„ç¾¤é«”é›¢è·ç‡æœ€é«˜ï¼Œé”åˆ° **{max_row['é›¢è·ç‡%']}%**ã€‚")
        else:
            # === ç›’é¬šåœ– (Box Plot) ===
            fig = px.box(df, x="é›¢è·", y=target_factor, color="é›¢è·", 
                         title=f"é›¢è·è€… vs åœ¨è·è€…çš„ã€{target_factor}ã€‘åˆ†ä½ˆå·®ç•°",
                         color_discrete_map={'æ˜¯':'#FF4B4B', 'å¦':'#1F77B4'})
            st.plotly_chart(fig, use_container_width=True)
            
            # å¹³å‡æ•¸æ¯”è¼ƒ
            avg_yes = df[df['é›¢è·']=='æ˜¯'][target_factor].mean()
            avg_no = df[df['é›¢è·']=='å¦'][target_factor].mean()
            diff_pct = ((avg_yes - avg_no) / avg_no) * 100
            
            m1, m2, m3 = st.columns(3)
            m1.metric("é›¢è·è€…å¹³å‡", f"{avg_yes:,.1f}")
            m2.metric("åœ¨è·è€…å¹³å‡", f"{avg_no:,.1f}")
            m3.metric("å·®ç•°å¹…åº¦", f"{diff_pct:+.1f}%", delta_color="inverse")

with col2:
    st.subheader("ğŸ”¥ ç›¸é—œæ€§ç†±åœ–")
    corr_cols = [c for c in factors if c in numeric_cols] + ['é›¢è·_æ•¸å€¼']
    corr_cols = list(set([c for c in corr_cols if c in df.columns]))
    
    if len(corr_cols) > 1:
        corr_matrix = df[corr_cols].corr()[['é›¢è·_æ•¸å€¼']].sort_values(by='é›¢è·_æ•¸å€¼', ascending=False)
        fig_corr = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
        st.plotly_chart(fig_corr, use_container_width=True)
        st.caption("ç´…è‰²=é›¢è·æ¨æ‰‹(æ­£ç›¸é—œ) | è—è‰²=ç•™ä»»å› å­(è² ç›¸é—œ)")
    else:
        st.warning("è«‹é¸æ“‡æ›´å¤šæ•¸å€¼å› å­ä»¥é¡¯ç¤ºç†±åœ–")

# ==========================================
# 3. AI é æ¸¬æ¨¡å‹
# ==========================================
st.divider()
st.header("2. AI é›¢è·é æ¸¬æ¨¡å‹ (Prediction)")

c_AI_1, c_AI_2 = st.columns(2)
with c_AI_1:
    st.write("è¨­å®šæ¨¡å‹åƒæ•¸ï¼Œè¨“ç·´ AI æ‰¾å‡ºé›¢è·é—œéµã€‚")
    n_estimators = st.slider("æ±ºç­–æ¨¹æ•¸é‡ (Trees)", 10, 200, 100)
    
    # ç°¡å–®ç‰¹å¾µå·¥ç¨‹
    drop_cols = ['é›¢è·', 'å“¡å·¥æ•¸é‡', 'å“¡å·¥ç·¨è™Ÿ', 'å¹´æ»¿18æ­²', 'æ¨™æº–å·¥æ™‚', 'é›¢è·_æ•¸å€¼']
    real_drop = [c for c in drop_cols if c in df.columns]
    df_ml = pd.get_dummies(df.drop(real_drop, axis=1), drop_first=True)
    
    if st.button("ğŸš€ è¨“ç·´ AI æ¨¡å‹"):
        X = df_ml
        y = df['é›¢è·_æ•¸å€¼']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        
        st.session_state['model_res'] = {'acc': acc, 'recall': recall, 'model': model, 'feat': X.columns}

with c_AI_2:
    if 'model_res' in st.session_state:
        res = st.session_state['model_res']
        st.subheader("ğŸ† æ¨¡å‹åˆ†æçµæœ")
        c1, c2 = st.columns(2)
        c1.metric("é æ¸¬æº–ç¢ºç‡", f"{res['acc']*100:.1f}%")
        c2.metric("å¬å›ç‡ (æŠ“åˆ°é›¢è·è€…)", f"{res['recall']*100:.1f}%")
        
        st.write("**AI èªç‚ºå½±éŸ¿é›¢è·çš„å‰ 5 å¤§é—œéµå› ç´ ï¼š**")
        imp = pd.Series(res['model'].feature_importances_, index=res['feat'])
        st.bar_chart(imp.nlargest(5), color='#ff4b4b')

# ==========================================
# 4. ç­–ç•¥ææ¡ˆèˆ‡è¨ºæ–· (æ”¹ç‚ºå‹¾é¸å¼)
# ==========================================
st.divider()
st.header("3. ç­–ç•¥ææ¡ˆèˆ‡è¨ºæ–·å ±å‘Š")
st.write("è«‹å„çµ„æ ¹æ“šä¸Šæ–¹çš„æ•¸æ“šåˆ†æçµæœï¼Œå‹¾é¸ä½ å€‘çš„ç™¼ç¾èˆ‡å»ºè­°ã€‚")

col_diag, col_act = st.columns(2)

with col_diag:
    st.subheader("ğŸ§ 3-1. æ•¸æ“šè¨ºæ–· (ä½ ç™¼ç¾äº†ä»€éº¼ï¼Ÿ)")
    findings = st.multiselect(
        "è«‹å‹¾é¸æ•¸æ“šé¡¯ç¤ºçš„é›¢è·ä¸»å›  (å¯è¤‡é¸)ï¼š",
        [
            "åŠ ç­ (OverTime) - é›¢è·ç‡é¡¯è‘—è¼ƒé«˜",
            "æœˆæ”¶å…¥ (Income) - é›¢è·è€…è–ªè³‡åä½",
            "å¹´é½¡ (Age) - å¹´è¼•å“¡å·¥æµå¤±ç‡é«˜",
            "å·¥ä½œæ»¿æ„åº¦ (Satisfaction) - ä½æ»¿æ„åº¦è€…æ˜“é›¢è·",
            "é€šå‹¤è·é›¢ (Distance) - ä½å¤ªé å®¹æ˜“é›¢è·",
            "è·ç´š (JobLevel) - åˆéšå“¡å·¥æµå‹•ç‡é«˜",
            "ç’°å¢ƒæ»¿æ„åº¦ (Environment) - å·¥ä½œç’°å¢ƒä¸ä½³",
            "å¹´è³‡ (YearsAtCompany) - æ–°é€²å“¡å·¥æ’ä¸ä¹…"
        ]
    )

with col_act:
    st.subheader("ğŸ’¡ 3-2. è¡Œå‹•æ–¹æ¡ˆ (ä½ å»ºè­°æ€éº¼åšï¼Ÿ)")
    actions = st.multiselect(
        "è«‹å‹¾é¸å»ºè­°æ¡å–çš„è¡Œå‹•æ–¹æ¡ˆ (å¯è¤‡é¸)ï¼š",
        [
            "åš´æ ¼æ§ç®¡åŠ ç­æ™‚æ•¸ï¼Œå¯¦æ–½æº–æ™‚ä¸‹ç­æ”¿ç­–",
            "èª¿æ•´é—œéµè·ä½è–ªè³‡ï¼Œç¢ºä¿å…·å‚™å¸‚å ´ç«¶çˆ­åŠ›",
            "é‡å°å¹´è¼•å“¡å·¥ (Gen Z) è¨­è¨ˆç•™æ‰è¨ˆç•«",
            "å„ªåŒ–æ–°é€²å“¡å·¥å…¥è·åŸ¹è¨“ (Onboarding)",
            "å¯¦æ–½é è·å·¥ä½œæˆ–å½ˆæ€§å·¥æ™‚ (è§£æ±ºé€šå‹¤å•é¡Œ)",
            "é€²è¡Œç•™ä»»è¨ªè«‡ (Stay Interview) äº†è§£ä¸æ»¿åŸå› ",
            "æ”¹å–„è¾¦å…¬å®¤ç’°å¢ƒèˆ‡è¨­æ–½",
            "å„ªå…ˆæ‹›è˜è³‡æ·±æˆ–ç©©å®šæ€§é«˜çš„äººæ‰"
        ]
    )

st.write("")
st.write("---")

# æäº¤æŒ‰éˆ•
if st.button("ğŸ“ æäº¤ç­–ç•¥åˆ†æå ±å‘Š", type="primary"):
    if not findings or not actions:
        st.error("âŒ è«‹è‡³å°‘å‹¾é¸ä¸€å€‹ã€Œç™¼ç¾ã€å’Œä¸€å€‹ã€Œè¡Œå‹•æ–¹æ¡ˆã€æ‰èƒ½æäº¤ï¼")
    else:
        st.balloons()
        st.success("âœ… å ±å‘Šå·²æˆåŠŸæäº¤ï¼")
        
        # ç”¢ç”Ÿè‡ªå‹•å›é¥‹
        st.markdown("### ğŸ¤– ã€AI åŠ©æ•™å›é¥‹ã€‘")
        st.write(f"ä½ å€‘çµ„ç™¼ç¾äº† **{len(findings)}** å€‹é—œéµå•é¡Œï¼Œä¸¦æå‡ºäº† **{len(actions)}** å€‹è§£æ±ºæ–¹æ¡ˆã€‚")
        
        # ç°¡å–®çš„é‚è¼¯æª¢æŸ¥å›é¥‹
        if "åŠ ç­ (OverTime) - é›¢è·ç‡é¡¯è‘—è¼ƒé«˜" in findings and "åš´æ ¼æ§ç®¡åŠ ç­æ™‚æ•¸ï¼Œå¯¦æ–½æº–æ™‚ä¸‹ç­æ”¿ç­–" in actions:
            st.info("ğŸ‘ **é‚è¼¯æ­£ç¢ºï¼** ä½ å€‘ç™¼ç¾äº†ã€ŒåŠ ç­ã€å•é¡Œï¼Œä¸¦å°æ‡‰æå‡ºäº†ã€Œæ§ç®¡å·¥æ™‚ã€çš„è§£æ³•ã€‚")
        elif "åŠ ç­ (OverTime) - é›¢è·ç‡é¡¯è‘—è¼ƒé«˜" in findings and "åš´æ ¼æ§ç®¡åŠ ç­æ™‚æ•¸ï¼Œå¯¦æ–½æº–æ™‚ä¸‹ç­æ”¿ç­–" not in actions:
            st.warning("âš ï¸ **æç¤ºï¼š** ä½ å€‘ç™¼ç¾äº†ã€ŒåŠ ç­ã€æ˜¯ä¸»å› ï¼Œä½†ä¼¼ä¹æ²’æœ‰æå‡ºå°æ‡‰çš„è§£æ±ºæ–¹æ¡ˆï¼Ÿå»ºè­°å‹¾é¸ã€Œæ§ç®¡åŠ ç­ã€ã€‚")
            
        if "æœˆæ”¶å…¥ (Income) - é›¢è·è€…è–ªè³‡åä½" in findings and "èª¿æ•´é—œéµè·ä½è–ªè³‡ï¼Œç¢ºä¿å…·å‚™å¸‚å ´ç«¶çˆ­åŠ›" in actions:
            st.info("ğŸ‘ **é‚è¼¯æ­£ç¢ºï¼** é‡å°è–ªè³‡å•é¡Œæå‡ºäº†èª¿è–ªç­–ç•¥ï¼Œé€™æ˜¯æœ€ç›´æ¥æœ‰æ•ˆçš„ç•™æ‰æ‰‹æ®µã€‚")
